{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659425bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"datasets/\"):\n",
    "    os.mkdir(\"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231cc3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-21 12:51:26--  http://cseweb.ucsd.edu/~wckang/steam_reviews.json.gz\n",
      "Resolving cseweb.ucsd.edu (cseweb.ucsd.edu)... 132.239.8.30\n",
      "Connecting to cseweb.ucsd.edu (cseweb.ucsd.edu)|132.239.8.30|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cseweb.ucsd.edu//~wckang/steam_reviews.json.gz [following]\n",
      "--2025-10-21 12:51:27--  https://cseweb.ucsd.edu//~wckang/steam_reviews.json.gz\n",
      "Connecting to cseweb.ucsd.edu (cseweb.ucsd.edu)|132.239.8.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1338063248 (1.2G) [application/x-gzip]\n",
      "Saving to: ‘datasets/steam_reviews.json.gz’\n",
      "\n",
      "datasets/steam_revi   0%[                    ]  11.19M   365KB/s    in 21s     \n",
      "\n",
      "2025-10-21 12:51:48 (542 KB/s) - Connection closed at byte 11730944. Retrying.\n",
      "\n",
      "--2025-10-21 12:51:49--  (try: 2)  https://cseweb.ucsd.edu//~wckang/steam_reviews.json.gz\n",
      "Connecting to cseweb.ucsd.edu (cseweb.ucsd.edu)|132.239.8.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 206 Partial Content\n",
      "Length: 1338063248 (1.2G), 1326332304 (1.2G) remaining [application/x-gzip]\n",
      "Saving to: ‘datasets/steam_reviews.json.gz’\n",
      "\n",
      "datasets/steam_revi 100%[===================>]   1.25G  5.36MB/s    in 2m 7s   \n",
      "\n",
      "2025-10-21 12:54:05 (9.96 MB/s) - ‘datasets/steam_reviews.json.gz’ saved [1338063248/1338063248]\n",
      "\n",
      "--2025-10-21 12:54:05--  http://cseweb.ucsd.edu/~wckang/steam_games.json.gz\n",
      "Resolving cseweb.ucsd.edu (cseweb.ucsd.edu)... 132.239.8.30\n",
      "Connecting to cseweb.ucsd.edu (cseweb.ucsd.edu)|132.239.8.30|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cseweb.ucsd.edu//~wckang/steam_games.json.gz [following]\n",
      "--2025-10-21 12:54:06--  https://cseweb.ucsd.edu//~wckang/steam_games.json.gz\n",
      "Connecting to cseweb.ucsd.edu (cseweb.ucsd.edu)|132.239.8.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2740516 (2.6M) [application/x-gzip]\n",
      "Saving to: ‘datasets/steam_games.json.gz’\n",
      "\n",
      "datasets/steam_game 100%[===================>]   2.61M   290KB/s    in 8.9s    \n",
      "\n",
      "2025-10-21 12:54:17 (300 KB/s) - ‘datasets/steam_games.json.gz’ saved [2740516/2740516]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"User-Agent: Mozilla/5.0\" -O datasets/steam_reviews.json.gz http://cseweb.ucsd.edu/~wckang/steam_reviews.json.gz\n",
    "!wget --header=\"User-Agent: Mozilla/5.0\" -O datasets/steam_games.json.gz http://cseweb.ucsd.edu/~wckang/steam_games.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cfef241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# Ruta del archivo .gz\n",
    "gz_path = \"datasets/steam_games.json.gz\"\n",
    "\n",
    "# Ruta de destino sin compresión\n",
    "output_path = \"datasets/steam_games.json\"\n",
    "\n",
    "# Descomprimir\n",
    "with gzip.open(gz_path, 'rb') as f_in:\n",
    "    with open(output_path, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "\n",
    "# Ruta del archivo .gz\n",
    "gz_path = \"datasets/steam_reviews.json.gz\"\n",
    "\n",
    "# Ruta de destino sin compresión\n",
    "output_path = \"datasets/steam_new.json\"\n",
    "\n",
    "# Descomprimir\n",
    "with gzip.open(gz_path, 'rb') as f_in:\n",
    "    with open(output_path, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "959e6ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de registros cargados en df_games: 32135\n",
      "\n",
      "Número total de registros cargados en df_reviews: 7793069\n"
     ]
    }
   ],
   "source": [
    "#codigo para cargar los datos en 2 df, uno para el game_info y otro para las reviews\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def json_line_generator(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                data_object = ast.literal_eval(line)\n",
    "                yield data_object\n",
    "\n",
    "\n",
    "df_games = pd.DataFrame(json_line_generator(\"datasets/steam_games.json\"))\n",
    "df_reviews = pd.DataFrame(json_line_generator(\"datasets/steam_new.json\"))\n",
    "print(\"Número total de registros cargados en df_games:\", len(df_games))\n",
    "\n",
    "print(\"\\nNúmero total de registros cargados en df_reviews:\", len(df_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "804038d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poner una columna de el nombre del juego en el df de reviews\n",
    "df_games_info = df_games[['id', 'title']].rename(columns={'id': 'product_id', 'title': 'game_title'})\n",
    "df_reviews = pd.merge(\n",
    "    df_reviews,                       \n",
    "    df_games_info,                    \n",
    "    on='product_id',                  \n",
    "    how='left'                        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cafc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>hours</th>\n",
       "      <th>products</th>\n",
       "      <th>product_id</th>\n",
       "      <th>page_order</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>early_access</th>\n",
       "      <th>page</th>\n",
       "      <th>found_funny</th>\n",
       "      <th>compensation</th>\n",
       "      <th>user_id</th>\n",
       "      <th>game_title</th>\n",
       "      <th>processed_tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chaos Syren</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>725280</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>This would not be acceptable as an entertainme...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Psi Project</td>\n",
       "      <td>[would, acceptable, entertainment, even, back,...</td>\n",
       "      <td>would acceptable entertainment even back day g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>₮ʜᴇ Wᴀʀᴛᴏɴ</td>\n",
       "      <td>51.1</td>\n",
       "      <td>769.0</td>\n",
       "      <td>328100</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>looks like a facebook game</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunspell - Steam Edition</td>\n",
       "      <td>[looks, like, facebook, game]</td>\n",
       "      <td>looks like facebook game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello?&lt;</td>\n",
       "      <td>14.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>328100</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>Better than Minecraft</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Product received for free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunspell - Steam Edition</td>\n",
       "      <td>[better, minecraft]</td>\n",
       "      <td>better minecraft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cyderine916</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35140</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>I love and idolized Batman and this game is Ma...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Batman: Arkham Asylum Game of the Year Edition</td>\n",
       "      <td>[love, idolized, batman, game, masterpiece]</td>\n",
       "      <td>love idolized batman game masterpiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DarklyThinking</td>\n",
       "      <td>16.6</td>\n",
       "      <td>577.0</td>\n",
       "      <td>35140</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>Still worth playing in 2018.\\nProbably my favo...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76561198007483075</td>\n",
       "      <td>Batman: Arkham Asylum Game of the Year Edition</td>\n",
       "      <td>[still, worth, playing, probably, favorite, ba...</td>\n",
       "      <td>still worth playing probably favorite batman g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username  hours  products product_id  page_order        date  \\\n",
       "0     Chaos Syren    0.1      41.0     725280           0  2017-12-17   \n",
       "1      ₮ʜᴇ Wᴀʀᴛᴏɴ   51.1     769.0     328100           0  2017-12-27   \n",
       "2         hello?<   14.6       2.0     328100           1  2017-10-16   \n",
       "3     Cyderine916    5.0      64.0      35140           0  2018-01-04   \n",
       "4  DarklyThinking   16.6     577.0      35140           1  2018-01-04   \n",
       "\n",
       "                                                text  early_access  page  \\\n",
       "0  This would not be acceptable as an entertainme...         False     1   \n",
       "1                         looks like a facebook game         False     1   \n",
       "2                              Better than Minecraft         False     1   \n",
       "3  I love and idolized Batman and this game is Ma...         False     1   \n",
       "4  Still worth playing in 2018.\\nProbably my favo...         False     1   \n",
       "\n",
       "   found_funny               compensation            user_id  \\\n",
       "0          NaN                        NaN                NaN   \n",
       "1          NaN                        NaN                NaN   \n",
       "2          2.0  Product received for free                NaN   \n",
       "3          NaN                        NaN                NaN   \n",
       "4          NaN                        NaN  76561198007483075   \n",
       "\n",
       "                                       game_title  \\\n",
       "0                                     Psi Project   \n",
       "1                        Gunspell - Steam Edition   \n",
       "2                        Gunspell - Steam Edition   \n",
       "3  Batman: Arkham Asylum Game of the Year Edition   \n",
       "4  Batman: Arkham Asylum Game of the Year Edition   \n",
       "\n",
       "                                    processed_tokens  \\\n",
       "0  [would, acceptable, entertainment, even, back,...   \n",
       "1                      [looks, like, facebook, game]   \n",
       "2                                [better, minecraft]   \n",
       "3        [love, idolized, batman, game, masterpiece]   \n",
       "4  [still, worth, playing, probably, favorite, ba...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  would acceptable entertainment even back day g...  \n",
       "1                           looks like facebook game  \n",
       "2                                   better minecraft  \n",
       "3              love idolized batman game masterpiece  \n",
       "4  still worth playing probably favorite batman g...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificación\n",
    "df_reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8850a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if text is None or text == \"\":\n",
    "        return []\n",
    "    \n",
    "    #minuscula + ruido\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) #URLs\n",
    "    text = re.sub(r'<.*?>', '', text)       #etiquetas HTML\n",
    "    text = re.sub(r'[^a-záéíóúüñ\\s]', '', text) #caracteres no alfabéticos \n",
    "\n",
    "    #tokenizacion\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    #stopwords \n",
    "    spanish_stopwords = set(stopwords.words('spanish'))\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    all_stopwords = spanish_stopwords.union(english_stopwords)\n",
    "\n",
    "    filtered_tokens = [word for word in tokens if word not in all_stopwords and len(word) > 1]\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "df_reviews['processed_tokens'] = df_reviews['text'].apply(preprocess_text)\n",
    "df_reviews['processed_text'] = df_reviews['processed_tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735ec980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>hours</th>\n",
       "      <th>products</th>\n",
       "      <th>product_id</th>\n",
       "      <th>page_order</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>early_access</th>\n",
       "      <th>page</th>\n",
       "      <th>found_funny</th>\n",
       "      <th>compensation</th>\n",
       "      <th>user_id</th>\n",
       "      <th>game_title</th>\n",
       "      <th>processed_tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chaos Syren</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>725280</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>This would not be acceptable as an entertainme...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Psi Project</td>\n",
       "      <td>[would, acceptable, entertainment, even, back,...</td>\n",
       "      <td>would acceptable entertainment even back day g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>₮ʜᴇ Wᴀʀᴛᴏɴ</td>\n",
       "      <td>51.1</td>\n",
       "      <td>769.0</td>\n",
       "      <td>328100</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>looks like a facebook game</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunspell - Steam Edition</td>\n",
       "      <td>[looks, like, facebook, game]</td>\n",
       "      <td>looks like facebook game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello?&lt;</td>\n",
       "      <td>14.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>328100</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>Better than Minecraft</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Product received for free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunspell - Steam Edition</td>\n",
       "      <td>[better, minecraft]</td>\n",
       "      <td>better minecraft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cyderine916</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35140</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>I love and idolized Batman and this game is Ma...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Batman: Arkham Asylum Game of the Year Edition</td>\n",
       "      <td>[love, idolized, batman, game, masterpiece]</td>\n",
       "      <td>love idolized batman game masterpiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DarklyThinking</td>\n",
       "      <td>16.6</td>\n",
       "      <td>577.0</td>\n",
       "      <td>35140</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>Still worth playing in 2018.\\nProbably my favo...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76561198007483075</td>\n",
       "      <td>Batman: Arkham Asylum Game of the Year Edition</td>\n",
       "      <td>[still, worth, playing, probably, favorite, ba...</td>\n",
       "      <td>still worth playing probably favorite batman g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username  hours  products product_id  page_order        date  \\\n",
       "0     Chaos Syren    0.1      41.0     725280           0  2017-12-17   \n",
       "1      ₮ʜᴇ Wᴀʀᴛᴏɴ   51.1     769.0     328100           0  2017-12-27   \n",
       "2         hello?<   14.6       2.0     328100           1  2017-10-16   \n",
       "3     Cyderine916    5.0      64.0      35140           0  2018-01-04   \n",
       "4  DarklyThinking   16.6     577.0      35140           1  2018-01-04   \n",
       "\n",
       "                                                text  early_access  page  \\\n",
       "0  This would not be acceptable as an entertainme...         False     1   \n",
       "1                         looks like a facebook game         False     1   \n",
       "2                              Better than Minecraft         False     1   \n",
       "3  I love and idolized Batman and this game is Ma...         False     1   \n",
       "4  Still worth playing in 2018.\\nProbably my favo...         False     1   \n",
       "\n",
       "   found_funny               compensation            user_id  \\\n",
       "0          NaN                        NaN                NaN   \n",
       "1          NaN                        NaN                NaN   \n",
       "2          2.0  Product received for free                NaN   \n",
       "3          NaN                        NaN                NaN   \n",
       "4          NaN                        NaN  76561198007483075   \n",
       "\n",
       "                                       game_title  \\\n",
       "0                                     Psi Project   \n",
       "1                        Gunspell - Steam Edition   \n",
       "2                        Gunspell - Steam Edition   \n",
       "3  Batman: Arkham Asylum Game of the Year Edition   \n",
       "4  Batman: Arkham Asylum Game of the Year Edition   \n",
       "\n",
       "                                    processed_tokens  \\\n",
       "0  [would, acceptable, entertainment, even, back,...   \n",
       "1                      [looks, like, facebook, game]   \n",
       "2                                [better, minecraft]   \n",
       "3        [love, idolized, batman, game, masterpiece]   \n",
       "4  [still, worth, playing, probably, favorite, ba...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  would acceptable entertainment even back day g...  \n",
       "1                           looks like facebook game  \n",
       "2                                   better minecraft  \n",
       "3              love idolized batman game masterpiece  \n",
       "4  still worth playing probably favorite batman g...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7bf115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de reviews procesadas: 7671591\n",
      "Loss after epoch 0: 62963780.0\n",
      "Loss after epoch 1: 12603356.0\n",
      "Loss after epoch 2: 9321936.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#crear Word2Vec\u001b[39;00m\n\u001b[32m     30\u001b[39m epoch_logger = EpochLogger()\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m model = \u001b[43mgensim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWord2Vec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m=\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mepoch_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m  \u001b[49m\n\u001b[32m     42\u001b[39m \n\u001b[32m     43\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mVocabulario construido con \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(model.wv)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m palabras únicas\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Visualización con TSNE\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Selecciona las primeras 200 palabras más frecuentes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4/NL/venvNL/lib/python3.12/site-packages/gensim/models/word2vec.py:430\u001b[39m, in \u001b[36mWord2Vec.__init__\u001b[39m\u001b[34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[39m\n\u001b[32m    428\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_corpus_sanity(corpus_iterable=corpus_iterable, corpus_file=corpus_file, passes=(epochs + \u001b[32m1\u001b[39m))\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m.build_vocab(corpus_iterable=corpus_iterable, corpus_file=corpus_file, trim_rule=trim_rule)\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcorpus_total_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmin_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trim_rule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4/NL/venvNL/lib/python3.12/site-packages/gensim/models/word2vec.py:1073\u001b[39m, in \u001b[36mWord2Vec.train\u001b[39m\u001b[34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1070\u001b[39m     callback.on_epoch_begin(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1078\u001b[39m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = \u001b[38;5;28mself\u001b[39m._train_epoch_corpusfile(\n\u001b[32m   1079\u001b[39m         corpus_file, cur_epoch=cur_epoch, total_examples=total_examples, total_words=total_words,\n\u001b[32m   1080\u001b[39m         callbacks=callbacks, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4/NL/venvNL/lib/python3.12/site-packages/gensim/models/word2vec.py:1434\u001b[39m, in \u001b[36mWord2Vec._train_epoch\u001b[39m\u001b[34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[39m\n\u001b[32m   1431\u001b[39m     thread.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[32m   1432\u001b[39m     thread.start()\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m trained_word_count, raw_word_count, job_tally = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_epoch_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_corpus_file_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4/NL/venvNL/lib/python3.12/site-packages/gensim/models/word2vec.py:1289\u001b[39m, in \u001b[36mWord2Vec._log_epoch_progress\u001b[39m\u001b[34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[39m\n\u001b[32m   1286\u001b[39m unfinished_worker_count = \u001b[38;5;28mself\u001b[39m.workers\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished_worker_count > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1289\u001b[39m     report = \u001b[43mprogress_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# blocks if workers too slow\u001b[39;00m\n\u001b[32m   1290\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# a thread reporting that it finished\u001b[39;00m\n\u001b[32m   1291\u001b[39m         unfinished_worker_count -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/queue.py:171\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a non-negative number\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#Crear word2vec con los tokens procesados\n",
    "\n",
    "import gensim.models\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss - self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss\n",
    "\n",
    "sentences = [tokens for tokens in df_reviews['processed_tokens'].values if len(tokens) > 0]\n",
    "\n",
    "print(f\"Número total de reviews procesadas: {len(sentences)}\")\n",
    "\n",
    "#crear Word2Vec\n",
    "epoch_logger = EpochLogger()\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "    sentences=sentences, \n",
    "    vector_size=200, \n",
    "    window=5, \n",
    "    min_count=5,  \n",
    "    compute_loss=True, \n",
    "    callbacks=[epoch_logger], \n",
    "    negative=5, \n",
    "    epochs=10,  \n",
    "    workers=4  \n",
    "    \n",
    ")\n",
    "\n",
    "print(f\"\\nVocabulario construido con {len(model.wv)} palabras únicas\")\n",
    "\n",
    "# Visualización con TSNE\n",
    "# Selecciona las primeras 200 palabras más frecuentes\n",
    "words = list(model.wv.index_to_key)[:200]\n",
    "vectors = [model.wv[word] for word in words]\n",
    "\n",
    "# Aplica TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0, perplexity=30)\n",
    "tsne_vectors = tsne.fit_transform(np.array(vectors))\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.scatter(tsne_vectors[:, 0], tsne_vectors[:, 1])\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, (tsne_vectors[i, 0], tsne_vectors[i, 1]))\n",
    "\n",
    "plt.title('Word2Vec - Steam Reviews')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65473314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplos de palabras similares\n",
      "\n",
      "Palabras similares a 'game':\n",
      "  gameit: 0.5682\n",
      "  title: 0.5607\n",
      "  games: 0.5594\n",
      "  gamebut: 0.5336\n",
      "  however: 0.5095\n",
      "\n",
      "Palabras similares a 'good':\n",
      "  decent: 0.8051\n",
      "  great: 0.7938\n",
      "  nice: 0.7174\n",
      "  awesome: 0.6665\n",
      "  solid: 0.6446\n",
      "\n",
      "Palabras similares a 'bad':\n",
      "  terrible: 0.7714\n",
      "  horrible: 0.7190\n",
      "  awful: 0.6701\n",
      "  poor: 0.6377\n",
      "  good: 0.6309\n",
      "\n",
      "Palabras similares a 'fun':\n",
      "  enjoyable: 0.7235\n",
      "  entertaining: 0.6970\n",
      "  addicting: 0.6465\n",
      "  addictive: 0.5959\n",
      "  funthe: 0.5762\n",
      "\n",
      "Palabras similares a 'play':\n",
      "  paly: 0.6889\n",
      "  playing: 0.6792\n",
      "  toaround: 0.5251\n",
      "  playbut: 0.5040\n",
      "  played: 0.4951\n"
     ]
    }
   ],
   "source": [
    "#ejemplos\n",
    "print(\"\\nEjemplos de palabras similares\")\n",
    "test_words = ['game', 'good', 'bad', 'fun', 'play']\n",
    "for word in test_words:\n",
    "    if word in model.wv:\n",
    "        print(f\"\\nPalabras similares a '{word}':\")\n",
    "        similar = model.wv.most_similar(word, topn=5)\n",
    "        for similar_word, score in similar:\n",
    "            print(f\"  {similar_word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37e44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo guardado como 'steam_reviews_w2v_model'\n"
     ]
    }
   ],
   "source": [
    "#guardar modelo\n",
    "import os\n",
    "if not os.path.exists(\"modelos/\"):\n",
    "    os.mkdir(\"modelos\")\n",
    "model.save(\"modelos/steam_reviews_w2v_model\")\n",
    "print(\"\\nModelo guardado como 'steam_reviews_w2v_model'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a9aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando vectores de documento para cada review...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizando: 100%|██████████| 7799538/7799538 [03:57<00:00, 32874.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Creando vectores de documento para cada review...\")\n",
    "\n",
    "def vectorize_documents(tokens_series, model):\n",
    "    \"\"\"\n",
    "    Método más rápido: procesamiento vectorizado con numpy\n",
    "    \"\"\"\n",
    "    vector_size = model.vector_size\n",
    "    n_docs = len(tokens_series)\n",
    "    \n",
    "    # Pre-alocar array para mejor rendimiento\n",
    "    doc_vectors = np.zeros((n_docs, vector_size), dtype=np.float32)\n",
    "    \n",
    "    # Procesar con barra de progreso\n",
    "    for i, tokens in enumerate(tqdm(tokens_series, desc=\"Vectorizando\")):\n",
    "        if tokens:\n",
    "            # Obtener vectores válidos de una vez\n",
    "            valid_vectors = np.array([model.wv[token] for token in tokens if token in model.wv])\n",
    "            \n",
    "            if len(valid_vectors) > 0:\n",
    "                doc_vectors[i] = valid_vectors.mean(axis=0)\n",
    "    \n",
    "    return doc_vectors\n",
    "\n",
    "# Aplicar\n",
    "doc_vectors = vectorize_documents(df_reviews['processed_tokens'], model)\n",
    "np.save('datasets/review_vectors.npy', doc_vectors)  \n",
    "del doc_vectors  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "127882b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>hours</th>\n",
       "      <th>products</th>\n",
       "      <th>product_id</th>\n",
       "      <th>page_order</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>early_access</th>\n",
       "      <th>page</th>\n",
       "      <th>found_funny</th>\n",
       "      <th>compensation</th>\n",
       "      <th>user_id</th>\n",
       "      <th>game_title</th>\n",
       "      <th>processed_tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chaos Syren</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>725280</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>This would not be acceptable as an entertainme...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Psi Project</td>\n",
       "      <td>[would, acceptable, entertainment, even, back,...</td>\n",
       "      <td>would acceptable entertainment even back day g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>₮ʜᴇ Wᴀʀᴛᴏɴ</td>\n",
       "      <td>51.1</td>\n",
       "      <td>769.0</td>\n",
       "      <td>328100</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>looks like a facebook game</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunspell - Steam Edition</td>\n",
       "      <td>[looks, like, facebook, game]</td>\n",
       "      <td>looks like facebook game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello?&lt;</td>\n",
       "      <td>14.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>328100</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>Better than Minecraft</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Product received for free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunspell - Steam Edition</td>\n",
       "      <td>[better, minecraft]</td>\n",
       "      <td>better minecraft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cyderine916</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35140</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>I love and idolized Batman and this game is Ma...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Batman: Arkham Asylum Game of the Year Edition</td>\n",
       "      <td>[love, idolized, batman, game, masterpiece]</td>\n",
       "      <td>love idolized batman game masterpiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DarklyThinking</td>\n",
       "      <td>16.6</td>\n",
       "      <td>577.0</td>\n",
       "      <td>35140</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>Still worth playing in 2018.\\nProbably my favo...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76561198007483075</td>\n",
       "      <td>Batman: Arkham Asylum Game of the Year Edition</td>\n",
       "      <td>[still, worth, playing, probably, favorite, ba...</td>\n",
       "      <td>still worth playing probably favorite batman g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username  hours  products product_id  page_order        date  \\\n",
       "0     Chaos Syren    0.1      41.0     725280           0  2017-12-17   \n",
       "1      ₮ʜᴇ Wᴀʀᴛᴏɴ   51.1     769.0     328100           0  2017-12-27   \n",
       "2         hello?<   14.6       2.0     328100           1  2017-10-16   \n",
       "3     Cyderine916    5.0      64.0      35140           0  2018-01-04   \n",
       "4  DarklyThinking   16.6     577.0      35140           1  2018-01-04   \n",
       "\n",
       "                                                text  early_access  page  \\\n",
       "0  This would not be acceptable as an entertainme...         False     1   \n",
       "1                         looks like a facebook game         False     1   \n",
       "2                              Better than Minecraft         False     1   \n",
       "3  I love and idolized Batman and this game is Ma...         False     1   \n",
       "4  Still worth playing in 2018.\\nProbably my favo...         False     1   \n",
       "\n",
       "   found_funny               compensation            user_id  \\\n",
       "0          NaN                        NaN                NaN   \n",
       "1          NaN                        NaN                NaN   \n",
       "2          2.0  Product received for free                NaN   \n",
       "3          NaN                        NaN                NaN   \n",
       "4          NaN                        NaN  76561198007483075   \n",
       "\n",
       "                                       game_title  \\\n",
       "0                                     Psi Project   \n",
       "1                        Gunspell - Steam Edition   \n",
       "2                        Gunspell - Steam Edition   \n",
       "3  Batman: Arkham Asylum Game of the Year Edition   \n",
       "4  Batman: Arkham Asylum Game of the Year Edition   \n",
       "\n",
       "                                    processed_tokens  \\\n",
       "0  [would, acceptable, entertainment, even, back,...   \n",
       "1                      [looks, like, facebook, game]   \n",
       "2                                [better, minecraft]   \n",
       "3        [love, idolized, batman, game, masterpiece]   \n",
       "4  [still, worth, playing, probably, favorite, ba...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  would acceptable entertainment even back day g...  \n",
       "1                           looks like facebook game  \n",
       "2                                   better minecraft  \n",
       "3              love idolized batman game masterpiece  \n",
       "4  still worth playing probably favorite batman g...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f485c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060\n",
      "VRAM disponible: 8.59 GB\n",
      "\n",
      "Seleccionando muestra aleatoria de 1,000,000 reviews...\n",
      "Procesando 1,000,000 reviews en batches de 128\n",
      "Total de batches: 7,813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT embeddings:  10%|█         | 782/7813 [06:06<5:37:45,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Checkpoint: chunk 0 (100,096 procesadas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT embeddings:  20%|██        | 1564/7813 [12:13<5:36:27,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Checkpoint: chunk 1 (200,192 procesadas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT embeddings:  30%|███       | 2346/7813 [18:25<4:43:03,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Checkpoint: chunk 2 (300,288 procesadas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT embeddings:  40%|████      | 3128/7813 [24:38<4:08:17,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Checkpoint: chunk 3 (400,384 procesadas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT embeddings:  50%|█████     | 3910/7813 [30:47<2:52:31,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Checkpoint: chunk 4 (500,480 procesadas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT embeddings:  60%|██████    | 4692/7813 [36:52<2:39:44,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Checkpoint: chunk 5 (600,576 procesadas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT embeddings:  70%|███████   | 5474/7813 [42:57<1:54:53,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Checkpoint: chunk 6 (700,672 procesadas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT embeddings:  80%|████████  | 6256/7813 [49:01<1:15:10,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Checkpoint: chunk 7 (800,768 procesadas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT embeddings:  90%|█████████ | 7038/7813 [55:06<32:40,  2.53s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Checkpoint: chunk 8 (900,864 procesadas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT embeddings: 100%|██████████| 7813/7813 [1:01:24<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Guardando embeddings finales...\n",
      "\n",
      "✅ 1,000,000 embeddings BERT generados\n",
      "Archivos guardados:\n",
      "  - datasets/bert_embeddings_1M.npy (embeddings)\n",
      "  - datasets/bert_sample_indices.npy (índices de la muestra)\n",
      "\n",
      "Para usar después:\n",
      "bert_embeds = np.load('datasets/bert_embeddings_1M.npy')\n",
      "indices = np.load('datasets/bert_sample_indices.npy')\n",
      "df_sample = df_reviews.iloc[indices]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Habilitar optimizaciones\n",
    "if device.type == 'cuda':\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "def get_bert_embeddings_batch(texts_batch):\n",
    "    inputs = tokenizer(texts_batch, return_tensors='pt', truncation=True, \n",
    "                      padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "# TOMAR MUESTRA DE 1M REVIEWS\n",
    "SAMPLE_SIZE = 1000000\n",
    "print(f\"\\nSeleccionando muestra aleatoria de {SAMPLE_SIZE:,} reviews...\")\n",
    "sample_indices = np.random.choice(len(df_reviews), SAMPLE_SIZE, replace=False)\n",
    "texts = df_reviews.iloc[sample_indices]['processed_text'].tolist()\n",
    "\n",
    "# PROCESAMIENTO OPTIMIZADO\n",
    "batch_size = 128\n",
    "total_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "\n",
    "print(f\"Procesando {len(texts):,} reviews en batches de {batch_size}\")\n",
    "print(f\"Total de batches: {total_batches:,}\")\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "# Guardar por chunks\n",
    "chunk_size = 100000\n",
    "current_chunk = []\n",
    "chunk_num = 0\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size), desc=\"BERT embeddings\", total=total_batches):\n",
    "    batch = texts[i:i + batch_size]\n",
    "    batch_embeddings = get_bert_embeddings_batch(batch)\n",
    "    current_chunk.extend(batch_embeddings)\n",
    "    \n",
    "    # Guardar checkpoint cada 100k\n",
    "    if len(current_chunk) >= chunk_size:\n",
    "        embeddings.extend(current_chunk)\n",
    "        \n",
    "        np.save(f'datasets/bert_embeddings_chunk_{chunk_num}.npy', np.array(current_chunk))\n",
    "        print(f\"\\n✅ Checkpoint: chunk {chunk_num} ({len(embeddings):,} procesadas)\")\n",
    "        \n",
    "        current_chunk = []\n",
    "        chunk_num += 1\n",
    "        gc.collect()\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Guardar último chunk\n",
    "if current_chunk:\n",
    "    embeddings.extend(current_chunk)\n",
    "    np.save(f'datasets/bert_embeddings_chunk_{chunk_num}.npy', np.array(current_chunk))\n",
    "\n",
    "# Guardar todo junto\n",
    "print(\"\\nGuardando embeddings finales...\")\n",
    "np.save('datasets/bert_embeddings_1M.npy', np.array(embeddings))\n",
    "np.save('datasets/bert_sample_indices.npy', sample_indices)\n",
    "\n",
    "print(f\"\\n✅ {len(embeddings):,} embeddings BERT generados\")\n",
    "print(\"Archivos guardados:\")\n",
    "print(\"  - datasets/bert_embeddings_1M.npy (embeddings)\")\n",
    "print(\"  - datasets/bert_sample_indices.npy (índices de la muestra)\")\n",
    "print(\"\\nPara usar después:\")\n",
    "print(\"bert_embeds = np.load('datasets/bert_embeddings_1M.npy')\")\n",
    "print(\"indices = np.load('datasets/bert_sample_indices.npy')\")\n",
    "print(\"df_sample = df_reviews.iloc[indices]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe11bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>hours</th>\n",
       "      <th>products</th>\n",
       "      <th>product_id</th>\n",
       "      <th>page_order</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>early_access</th>\n",
       "      <th>page</th>\n",
       "      <th>found_funny</th>\n",
       "      <th>compensation</th>\n",
       "      <th>user_id</th>\n",
       "      <th>game_title</th>\n",
       "      <th>processed_tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147788</th>\n",
       "      <td>Eric</td>\n",
       "      <td>0.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>461560</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-08-08</td>\n",
       "      <td>I am not entirely sure what I just experienced...</td>\n",
       "      <td>False</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MANDAGON</td>\n",
       "      <td>[entirely, sure, experienced, enjoyed, game, a...</td>\n",
       "      <td>entirely sure experienced enjoyed game atmosph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752600</th>\n",
       "      <td>joekerwuzhere</td>\n",
       "      <td>9.9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>369370</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-05</td>\n",
       "      <td>It was different than what I first expected, b...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76561198055199615</td>\n",
       "      <td>Crossfire: Dungeons</td>\n",
       "      <td>[different, first, expected, cool, turnbased, ...</td>\n",
       "      <td>different first expected cool turnbased tactic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591515</th>\n",
       "      <td>Danger Noodle</td>\n",
       "      <td>87.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>319630</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-03-30</td>\n",
       "      <td>this game is amazing, im having so much fun pl...</td>\n",
       "      <td>False</td>\n",
       "      <td>4691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76561198122059792</td>\n",
       "      <td>Life is Strange - Episode 1</td>\n",
       "      <td>[game, amazing, im, much, fun, playing, dont, ...</td>\n",
       "      <td>game amazing im much fun playing dont need rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660373</th>\n",
       "      <td>Elliot</td>\n",
       "      <td>7.1</td>\n",
       "      <td>229.0</td>\n",
       "      <td>41800</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>broken and devs screwed us all over</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gratuitous Space Battles</td>\n",
       "      <td>[broken, devs, screwed, us]</td>\n",
       "      <td>broken devs screwed us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733955</th>\n",
       "      <td>Jonas | iNFlames</td>\n",
       "      <td>15.9</td>\n",
       "      <td>117.0</td>\n",
       "      <td>383150</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-07-02</td>\n",
       "      <td>AWESOME</td>\n",
       "      <td>False</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dead Island Definitive Edition</td>\n",
       "      <td>[awesome]</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 username  hours  products product_id  page_order        date  \\\n",
       "147788               Eric    0.6      65.0     461560           6  2016-08-08   \n",
       "2752600     joekerwuzhere    9.9      28.0     369370           2  2015-06-05   \n",
       "1591515     Danger Noodle   87.2      33.0     319630           7  2015-03-30   \n",
       "3660373            Elliot    7.1     229.0      41800           1  2015-12-06   \n",
       "2733955  Jonas | iNFlames   15.9     117.0     383150           1  2017-07-02   \n",
       "\n",
       "                                                      text  early_access  \\\n",
       "147788   I am not entirely sure what I just experienced...         False   \n",
       "2752600  It was different than what I first expected, b...         False   \n",
       "1591515  this game is amazing, im having so much fun pl...         False   \n",
       "3660373                broken and devs screwed us all over         False   \n",
       "2733955                                            AWESOME         False   \n",
       "\n",
       "         page  found_funny compensation            user_id  \\\n",
       "147788    251          NaN          NaN                NaN   \n",
       "2752600     3          2.0          NaN  76561198055199615   \n",
       "1591515  4691          NaN          NaN  76561198122059792   \n",
       "3660373     8          NaN          NaN                NaN   \n",
       "2733955    41          1.0          NaN                NaN   \n",
       "\n",
       "                             game_title  \\\n",
       "147788                         MANDAGON   \n",
       "2752600             Crossfire: Dungeons   \n",
       "1591515     Life is Strange - Episode 1   \n",
       "3660373        Gratuitous Space Battles   \n",
       "2733955  Dead Island Definitive Edition   \n",
       "\n",
       "                                          processed_tokens  \\\n",
       "147788   [entirely, sure, experienced, enjoyed, game, a...   \n",
       "2752600  [different, first, expected, cool, turnbased, ...   \n",
       "1591515  [game, amazing, im, much, fun, playing, dont, ...   \n",
       "3660373                        [broken, devs, screwed, us]   \n",
       "2733955                                          [awesome]   \n",
       "\n",
       "                                            processed_text  \n",
       "147788   entirely sure experienced enjoyed game atmosph...  \n",
       "2752600  different first expected cool turnbased tactic...  \n",
       "1591515  game amazing im much fun playing dont need rea...  \n",
       "3660373                             broken devs screwed us  \n",
       "2733955                                            awesome  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embeds = np.load('datasets/bert_embeddings_1M.npy')\n",
    "indices = np.load('datasets/bert_sample_indices.npy')\n",
    "df_sample = df_reviews.iloc[indices]\n",
    "df_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REVIEW ORIGINAL (índice 0):\n",
      "================================================================================\n",
      "Juego: Psi Project\n",
      "Usuario: Chaos Syren\n",
      "Texto: This would not be acceptable as an entertainment even back in the day when these graphics were all there was to be had. No effort has been made to bring the player into any story or even entertain....\n",
      "\n",
      "================================================================================\n",
      "TOP 5 REVIEWS SIMILARES:\n",
      "================================================================================\n",
      "\n",
      "1. Similitud: 0.6773\n",
      "   Juego: Max Payne\n",
      "   Usuario: ExtraLevel {ESB}\n",
      "   Texto: This game was revolutionary for its time and even 16 years later it is still very enjoyable to play. The story is great and the way it is delivered ma...\n",
      "\n",
      "2. Similitud: 0.6625\n",
      "   Juego: Moon Hunters\n",
      "   Usuario: ΩXphodus LenthΩ\n",
      "   Texto: So fantastic I wish the devs would return and make more content so I can play this game even more......\n",
      "\n",
      "3. Similitud: 0.6624\n",
      "   Juego: Deus Ex: Mankind Divided\n",
      "   Usuario: ChuToy_89\n",
      "   Texto: What I expected. I don't know about the full story, but with gameplay mechanics, an atmosphere, a near perfect launch, and with the level of choice an...\n",
      "\n",
      "4. Similitud: 0.6606\n",
      "   Juego: The Hat Man: Shadow Ward\n",
      "   Usuario: ^foX\n",
      "   Texto: After playing the game for an hour, it failed to make me even slightly interested in the story. the graphics are bad which i could overlook if the gam...\n",
      "\n",
      "5. Similitud: 0.6596\n",
      "   Juego: MISSING: An Interactive Thriller - Episode One\n",
      "   Usuario: kyzka\n",
      "   Texto: I want you to think of all the FMV games that have been released thus far, you can check them out for yourself here...\n",
      "Now think of how many of those ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_similar_reviews(review_index, df_reviews, top_n=5):\n",
    "    \"\"\"\n",
    "    Encuentra las reviews más similares a una dada\n",
    "    \"\"\"\n",
    "    \n",
    "    #similitud con todas las reviews\n",
    "    all_vectors = np.load('datasets/review_vectors.npy', mmap_mode='r')\n",
    "    target_vector = all_vectors[review_index].reshape(1, -1)\n",
    "    similarities = cosine_similarity(target_vector, all_vectors)[0]\n",
    "    \n",
    "    #más similares\n",
    "    similar_indices = similarities.argsort()[-top_n-1:-1][::-1]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"REVIEW ORIGINAL (índice {review_index}):\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Juego: {df_reviews.iloc[review_index]['game_title']}\")\n",
    "    print(f\"Usuario: {df_reviews.iloc[review_index]['username']}\")\n",
    "    print(f\"Texto: {df_reviews.iloc[review_index]['text'][:200]}...\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TOP {top_n} REVIEWS SIMILARES:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for i, idx in enumerate(similar_indices, 1):\n",
    "        print(f\"\\n{i}. Similitud: {similarities[idx]:.4f}\")\n",
    "        print(f\"   Juego: {df_reviews.iloc[idx]['game_title']}\")\n",
    "        print(f\"   Usuario: {df_reviews.iloc[idx]['username']}\")\n",
    "        print(f\"   Texto: {df_reviews.iloc[idx]['text'][:150]}...\")\n",
    "\n",
    "#ejemplo\n",
    "find_similar_reviews(0, df_reviews, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, df_reviews, model, top_n=10):\n",
    "    \"\"\"\n",
    "    Busca reviews similares a una consulta de texto\n",
    "    \"\"\"\n",
    "    #preprocesar la consulta\n",
    "    query_tokens = preprocess_text(query)\n",
    "    query_vector =vectorize_documents(query_tokens, model).reshape(1, -1)\n",
    "    \n",
    "    #calcular similitud\n",
    "    all_vectors = np.stack('datasets/review_vectors.npy', mmap_mode='r')\n",
    "    similarities = cosine_similarity(query_vector, all_vectors)[0]\n",
    "    \n",
    "    #top resultados\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"BÚSQUEDA: '{query}'\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for i, idx in enumerate(top_indices, 1):\n",
    "        print(f\"\\n{i}. Similitud: {similarities[idx]:.4f}\")\n",
    "        print(f\"   Juego: {df_reviews.iloc[idx]['game_title']}\")\n",
    "        print(f\"   Usuario: {df_reviews.iloc[idx]['username']}\")\n",
    "        print(f\"   Texto: {df_reviews.iloc[idx]['text'][:200]}...\")\n",
    "\n",
    "#ejemplos\n",
    "semantic_search(\"amazing graphics and gameplay\", df_reviews, model, top_n=5)\n",
    "semantic_search(\"terrible bugs and crashes\", df_reviews, model, top_n=5)\n",
    "semantic_search(\"great story multiplayer fun\", df_reviews, model, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codigo para crear json de usuarios\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_users_json(df_reviews, output_file='datasets/steam_usuarios.json'):\n",
    "    \"\"\"\n",
    "    Crea JSON con información agregada por usuario\n",
    "    \"\"\"\n",
    "    print(\"Creando JSON de usuarios...\")\n",
    "    \n",
    "    users_data = defaultdict(lambda: {\n",
    "        'username': None,\n",
    "        'user_id': None,\n",
    "        'games_played': [],\n",
    "        'review_indices': [],\n",
    "        'total_reviews': 0,\n",
    "        'total_hours': 0\n",
    "    })\n",
    "    \n",
    "    #procesar cada review\n",
    "    for idx, row in tqdm(df_reviews.iterrows(), total=len(df_reviews), desc=\"Procesando usuarios\"):\n",
    "        username = row['username']\n",
    "        user_id = row['user_id'] if pd.notna(row['user_id']) else None\n",
    "        game = row['game_title']\n",
    "        hours = row['hours'] if pd.notna(row['hours']) else 0\n",
    "        \n",
    "        #actualizar datos del usuario\n",
    "        users_data[username]['username'] = username\n",
    "        users_data[username]['user_id'] = user_id\n",
    "        \n",
    "        if game not in users_data[username]['games_played']:\n",
    "            users_data[username]['games_played'].append(game)\n",
    "        \n",
    "        users_data[username]['review_indices'].append(int(idx))\n",
    "        users_data[username]['total_reviews'] += 1\n",
    "        users_data[username]['total_hours'] += hours\n",
    "    \n",
    "    users_dict = {k: dict(v) for k, v in users_data.items()}\n",
    "    \n",
    "    #guardar JSON\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(users_dict, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"✅ JSON guardado en '{output_file}'\")\n",
    "    print(f\"   Total usuarios: {len(users_dict):,}\")\n",
    "    \n",
    "    return users_dict\n",
    "\n",
    "\n",
    "users_dict = create_users_json(df_reviews, 'datasets/steam_usuarios.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93167817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para el analisis de credibilidad, autoridad de cada usuario\n",
    "\n",
    "def analyze_user_credibility(df_reviews, users_json_file='steam_usuarios.json'):\n",
    "    \"\"\"\n",
    "    Calcula métricas de credibilidad por usuario y las guarda en el JSON\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"1. ANÁLISIS DE CREDIBILIDAD/AUTORIDAD\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    #cargar JSON existente\n",
    "    with open(users_json_file, 'r', encoding='utf-8') as f:\n",
    "        users = json.load(f)\n",
    "    \n",
    "    credibility_scores = []\n",
    "    \n",
    "    for username, data in tqdm(users.items(), desc=\"Calculando credibilidad\"):\n",
    "        review_indices = data['review_indices']\n",
    "        user_reviews = df_reviews.iloc[review_indices]\n",
    "        \n",
    "        #métricas de credibilidad\n",
    "        total_reviews = len(review_indices)\n",
    "        avg_hours = data['total_hours'] / total_reviews if total_reviews > 0 else 0\n",
    "        games_diversity = len(data['games_played'])\n",
    "        \n",
    "        #Score de credibilidad \n",
    "        credibility_score = (\n",
    "            np.log1p(total_reviews) * 0.3 +\n",
    "            np.log1p(avg_hours) * 0.4 +\n",
    "            np.log1p(games_diversity) * 0.3\n",
    "        )\n",
    "        \n",
    "        #AÑADIR CREDIBILIDAD AL JSON\n",
    "        users[username]['credibility_score'] = float(credibility_score)\n",
    "        users[username]['credibility_metrics'] = {\n",
    "            'avg_hours': float(avg_hours),\n",
    "            'games_diversity': int(games_diversity)\n",
    "        }\n",
    "        \n",
    "        credibility_scores.append({\n",
    "            'username': username,\n",
    "            'credibility_score': credibility_score,\n",
    "            'total_reviews': total_reviews,\n",
    "            'avg_hours': avg_hours,\n",
    "            'games_diversity': games_diversity\n",
    "        })\n",
    "    \n",
    "    #GUARDAR JSON ACTUALIZADO\n",
    "    with open(users_json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(users, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"JSON actualizado con scores de credibilidad en '{users_json_file}'\")\n",
    "    \n",
    "    #crear DataFrame y ordenar\n",
    "    cred_df = pd.DataFrame(credibility_scores).sort_values('credibility_score', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 usuarios más creíbles:\")\n",
    "    print(cred_df.head(10).to_string(index=False))\n",
    "    \n",
    "    cred_df.to_csv('user_credibility.csv', index=False)\n",
    "    print(\"CSV guardado en 'user_credibility.csv'\")\n",
    "    \n",
    "    return cred_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
